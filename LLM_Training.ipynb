{"cells":[{"cell_type":"markdown","metadata":{"id":"1HBb9bsQHoNp"},"source":["## GoEx Fine Tuning"]},{"cell_type":"markdown","metadata":{"id":"6NG_46p1HqwL"},"source":["This finetuned file covers the following APIs\n","\n","1. serpapi for GoogleSearch (refer HW3)\n","2. news_search for news search from newsapi.org (refer HW4)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1707,"status":"ok","timestamp":1734634176505,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"},"user_tz":300},"id":"PwsoAPc1UoYm","outputId":"e4347649-312c-4cdd-cb63-b6ce7ad792ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#mounting functions\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2835,"status":"ok","timestamp":1734585927328,"user":{"displayName":"Hassan Chughtai","userId":"14420848799407865990"},"user_tz":-240},"id":"6DjkAs_WDizy","outputId":"60ff0c50-0a34-4986-e555-509a91447b6a","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets==2.12.0 in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Collecting huggingface-hub==0.14.1\n","  Using cached huggingface_hub-0.14.1-py3-none-any.whl.metadata (7.6 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (1.26.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (17.0.0)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (0.3.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (4.65.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (0.70.14)\n","Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.11.1->datasets==2.12.0) (2024.10.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (3.11.10)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (24.2)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (0.18.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.12.0) (6.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (3.16.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (4.12.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.12.0) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.12.0) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.12.0) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.12.0) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.12.0) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.12.0) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.12.0) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.12.0) (1.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.12.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.12.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.12.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.12.0) (2024.12.14)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.12.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.12.0) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.12.0) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.12.0) (1.17.0)\n","Using cached huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","Installing collected packages: huggingface-hub\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.27.0\n","    Uninstalling huggingface-hub-0.27.0:\n","      Successfully uninstalled huggingface-hub-0.27.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","accelerate 1.2.1 requires huggingface-hub>=0.21.0, but you have huggingface-hub 0.14.1 which is incompatible.\n","diffusers 0.31.0 requires huggingface-hub>=0.23.2, but you have huggingface-hub 0.14.1 which is incompatible.\n","peft 0.14.0 requires huggingface-hub>=0.25.0, but you have huggingface-hub 0.14.1 which is incompatible.\n","sentence-transformers 3.3.1 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.14.1 which is incompatible.\n","sentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.28.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed huggingface-hub-0.14.1\n"]}],"source":["!pip install --upgrade datasets==2.12.0 huggingface-hub==0.14.1\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37174,"status":"ok","timestamp":1734634214887,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"},"user_tz":300},"id":"g9L-5rDm_I6N","outputId":"7ac2c82f-dd8e-40ec-bfdf-b32b0b4fe1d8","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers==4.28.1 in /usr/local/lib/python3.10/dist-packages (4.28.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2.32.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2024.12.14)\n","Requirement already satisfied: huggingface-hub==0.14.1 in /usr/local/lib/python3.10/dist-packages (0.14.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (3.16.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (2024.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (4.65.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (4.12.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.14.1) (24.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.14.1) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.14.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.14.1) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.14.1) (2024.12.14)\n","Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.16.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (18.1.8)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n","Requirement already satisfied: tqdm==4.65.0 in /usr/local/lib/python3.10/dist-packages (4.65.0)\n","Requirement already satisfied: prompt_toolkit==3.0.38 in /usr/local/lib/python3.10/dist-packages (3.0.38)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt_toolkit==3.0.38) (0.2.13)\n","Requirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Requirement already satisfied: accelerate==0.19.0 in /usr/local/lib/python3.10/dist-packages (0.19.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.19.0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.19.0) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.19.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.19.0) (6.0.2)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.19.0) (2.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (3.16.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.19.0) (2.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate==0.19.0) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate==0.19.0) (0.45.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.19.0) (3.31.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.19.0) (18.1.8)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate==0.19.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate==0.19.0) (1.3.0)\n","Requirement already satisfied: einops==0.7.0 in /usr/local/lib/python3.10/dist-packages (0.7.0)\n"]}],"source":["!pip install transformers==4.28.1\n","!pip install huggingface-hub==0.14.1\n","!pip install torch==2.0.1\n","!pip install tqdm==4.65.0\n","!pip install prompt_toolkit==3.0.38\n","!pip install sentencepiece==0.1.99\n","!pip install accelerate==0.19.0\n","!pip install einops==0.7.0\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1963,"status":"ok","timestamp":1734585950969,"user":{"displayName":"Hassan Chughtai","userId":"14420848799407865990"},"user_tz":-240},"id":"qqtxMBNBEB5e","outputId":"0fc92dba-de79-455f-f53f-ad1f5dbca1c5","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Name: datasets\n","Version: 2.12.0\n","Summary: HuggingFace community-driven open-source library of datasets\n","Home-page: https://github.com/huggingface/datasets\n","Author: HuggingFace Inc.\n","Author-email: thomas@huggingface.co\n","License: Apache 2.0\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: aiohttp, dill, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, pyarrow, pyyaml, requests, responses, tqdm, xxhash\n","Required-by: \n"]}],"source":["!pip show datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16157,"status":"ok","timestamp":1734585967122,"user":{"displayName":"Hassan Chughtai","userId":"14420848799407865990"},"user_tz":-240},"id":"EYh6hHy1FKta","outputId":"bfa711af-e37c-42c9-a44e-09f5147a0994"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","    \n","    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n","    Setting a new token will erase the existing one.\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Token: \n","Add token as git credential? (Y/n) n\n","Token is valid.\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["!huggingface-cli login\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6820,"status":"ok","timestamp":1734633856883,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"},"user_tz":300},"id":"B_ykG2pHVKOl","outputId":"141a4926-3ad4-4e60-dd85-bb785d0065ea","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bitsandbytes\n","  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n","Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\n","Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (3.1.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.47.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.67.1)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.2.1)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n","Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.27.0)\n","Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n","Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n","Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from flask) (1.9.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.21.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2024.12.14)\n","Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.45.0\n"]}],"source":["!pip install bitsandbytes peft flask"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5C4fSjqbYOum","outputId":"311fb5c1-c40e-4791-e53b-74b59f5a66de","executionInfo":{"status":"ok","timestamp":1734585977961,"user_tz":-240,"elapsed":1555,"user":{"displayName":"Hassan Chughtai","userId":"14420848799407865990"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Dec 19 05:26:17 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0              45W / 400W |      2MiB / 40960MiB |      0%      Default |\n","|                                         |                      |             Disabled |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["import torch\n","\n","torch.cuda.empty_cache()\n","!nvidia-smi\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3158,"status":"ok","timestamp":1734585995814,"user":{"displayName":"Hassan Chughtai","userId":"14420848799407865990"},"user_tz":-240},"id":"zA3Bjyoce3KG","outputId":"174a506f-c618-4fd0-c593-07980d53fbda","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: serpapi in /usr/local/lib/python3.10/dist-packages (0.1.5)\n","Requirement already satisfied: google-search-results in /usr/local/lib/python3.10/dist-packages (2.4.2)\n","Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n","Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\n","Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from serpapi) (2.32.3)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.25)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n","Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n","Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.18.4)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->serpapi) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->serpapi) (2.2.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (3.0.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"]}],"source":["!pip install serpapi google-search-results openai langchain streamlit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XN8NdO0DRW1a"},"outputs":[],"source":["# !pip install -U transformers==4.37 accelerate==0.21.0\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"elapsed":3680,"status":"error","timestamp":1734586002307,"user":{"displayName":"Hassan Chughtai","userId":"14420848799407865990"},"user_tz":-240},"id":"KpDiSN2rB7fj","outputId":"218807bc-5705-4125-ff4d-51d98ad313cb","collapsed":true},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-4b2236cb9092>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mNEWSAPI_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/W6998-DL/HW4/serpapi_key.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mSERPAPI_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Set up environment variables for SerpAPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Import required libraries\n","import os\n","import json\n","from serpapi import GoogleSearch\n","import requests\n","from datasets import Dataset\n","from sklearn.model_selection import train_test_split\n","\n","# Load API keys\n","with open('/content/drive/MyDrive/W6998-DL/HW4/newsapi_key.txt', 'r') as f:\n","    NEWSAPI_KEY = f.read().strip()\n","with open('/content/drive/MyDrive/W6998-DL/HW4/serpapi_key.txt', 'r') as f:\n","    SERPAPI_API_KEY = f.read().strip()\n","\n","# Set up environment variables for SerpAPI\n","os.environ[\"SERPAPI_API_KEY\"] = SERPAPI_API_KEY\n","\n","# Function to query SerpAPI\n","# Function to query SerpAPI\n","def query_serpapi(query):\n","    try:\n","        search = GoogleSearch({\"q\": query, \"api_key\": SERPAPI_API_KEY})\n","        results = search.get_dict().get(\"organic_results\", [])\n","\n","        # Safely extract 'title' and 'snippet', handle missing fields\n","        processed_results = []\n","        for result in results[:5]:  # Top 5 results\n","            title = result.get('title', 'No Title')\n","            snippet = result.get('snippet', 'No Description')\n","            processed_results.append(f\"{title}: {snippet}\")\n","\n","        return processed_results\n","    except Exception as e:\n","        print(f\"Error querying SerpAPI: {e}\")\n","        return []\n","\n","\n","# Function to query NewsAPI\n","def query_newsapi(topic):\n","    try:\n","        url = f\"https://newsapi.org/v2/everything?q={topic}&apiKey={NEWSAPI_KEY}&pageSize=5\"\n","        response = requests.get(url)\n","        articles = response.json().get(\"articles\", [])\n","        return [f\"{article['title']}: {article['description']}\" for article in articles]\n","    except Exception as e:\n","        print(f\"Error querying NewsAPI: {e}\")\n","        return []\n","\n","# Expanded queries and topics for diversity\n","queries = [\n","    \"Python programming\", \"latest technology\", \"healthcare innovations\",\n","    \"best laptops\", \"top programming languages\", \"machine learning trends\",\n","    \"deep learning frameworks\", \"data science in 2024\", \"tech startups\"\n","]\n","\n","topics = [\n","    \"AI\", \"climate change\", \"finance\", \"sports\", \"politics\",\n","    \"entertainment\", \"cryptocurrency\", \"startup funding\", \"global economy\",\n","    \"environmental conservation\", \"healthcare policies\", \"education reforms\"\n","]\n","\n","def generate_data():\n","    data = []\n","\n","    # Fetch SerpAPI data\n","    for query in queries:\n","        results = query_serpapi(query)\n","        if results:\n","            input_text = f\"Find Google search results for '{query}'.\"\n","            output_text = \"Here are the top Google search results:\\n\" + \"\\n\".join(\n","                [f\"{i + 1}. {result}\" for i, result in enumerate(results)]\n","            )\n","            data.append({\"input\": input_text, \"output\": output_text})\n","\n","    # Fetch NewsAPI data\n","    for topic in topics:\n","        articles = query_newsapi(topic)\n","        if articles:\n","            input_text = f\"Find news articles about '{topic}'.\"\n","            output_text = \"Here are some recent news articles:\\n\" + \"\\n\".join(\n","                [f\"{i + 1}. {article}\" for i, article in enumerate(articles)]\n","            )\n","            data.append({\"input\": input_text, \"output\": output_text})\n","\n","    return data\n","\n","\n","def save_datasets():\n","    print(\"Generating data...\")\n","    data = generate_data()\n","    while len(data) < 500:\n","        data += generate_data()\n","        print(f\"Generated {len(data)} samples so far...\")\n","\n","    print(f\"Final dataset size: {len(data)}\")\n","    train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n","\n","    os.makedirs(\"./datasets\", exist_ok=True)\n","    with open(\"./datasets/train.json\", \"w\") as train_file:\n","        json.dump(train_data, train_file, indent=2)\n","    with open(\"./datasets/val.json\", \"w\") as val_file:\n","        json.dump(val_data, val_file, indent=2)\n","\n","    print(\"Datasets saved successfully:\")\n","    print(\" - Train dataset: ./datasets/train.json\")\n","    print(\" - Validation dataset: ./datasets/val.json\")\n","\n","\n","save_datasets()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":599,"referenced_widgets":["b0cf5011544b4912b63edbc60e6d62be","750b30f20e884889b828feaab80157c0","dce6d0b1f44a49b691ca9a2da593348b","61508d0423f8494db196614cb61bc3fb","b77a66f690984e2da84b470ed424e537","a265a4fe32c444cea29678556071b6b6","75c82cc98a6f49c0bbe01f56d9be3422","9adce390bd05408693efa4ffa38c0ca4","d43f8aa79c8743e89b189c67adc58778","14046227eef14344a5766eb3976b473d","1ea29e3d899d4caa8fadfebe2e438581","d3da982024d74f299683633cf1a9108c","738b08da24cc4ad2820b21054819d3c2","102d7964cd8341899a640f98e602ca3a","239675070c0a40ec880a1d784414bb75","5c06a0690a7c4c89adfaaffdca1bc2d6","f2980273d9224e0eb66d1014ae7f7b67","6d627365d07040be8b56f975fcc245c7","6b3f3db07fab4c278236430c1edd4d2c","d777b7692cd948128a9b6e3e04106488","c31f52448ef7409dbff3665d345083be","0d76746510f1412a96eb1d3204f2f995","7a9fec0dd77748a7aedb8ea057f8f9bd","00fda95070974d5aa657f8c9a2f81671","30b4ba00f7ca4628ae50a5e439f03f07","87a36cc2f4d84eef86acd8119ca01505","b1b235e04fea48b08b77a62c64d03ca4","00b5b2faefe1446d88c72625f8b6cb9e","569d3bc76c34488cb51447dc4871c809","bd32a3e27f1d459ca9295d0365b49c2d","21cd70ca04ae4ef78e58639d0f4dc979","ca1011b33a12421f9295b14dcc22e4e8","ac4b3240b5ca4214a430b06a0a5e81de"]},"id":"al_MSBDjTi0q","executionInfo":{"status":"error","timestamp":1734586665239,"user_tz":-240,"elapsed":28834,"user":{"displayName":"Hassan Chughtai","userId":"14420848799407865990"}},"outputId":"469a0d19-d792-4900-a6a8-2767877b598d","collapsed":true},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0cf5011544b4912b63edbc60e6d62be"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of LlamaForCausalLM were not initialized from the model checkpoint at gorilla-llm/gorilla-openfunctions-v2 and are newly initialized: ['model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.29.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.25.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.28.self_attn.rotary_emb.inv_freq', 'model.layers.26.self_attn.rotary_emb.inv_freq', 'model.layers.27.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/403 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3da982024d74f299683633cf1a9108c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/101 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a9fec0dd77748a7aedb8ea057f8f9bd"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 782.00 MiB (GPU 0; 39.56 GiB total capacity; 35.73 GiB already allocated; 466.81 MiB free; 38.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-fdd7dee25891>\u001b[0m in \u001b[0;36m<cell line: 96>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# Save the fine-tuned model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m         )\n\u001b[0;32m-> 1662\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1663\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1994\u001b[0m                         \u001b[0moptimizer_was_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_before\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mscale_after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1996\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0moptimizer_was_run\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                                                f\"but got {result}.\")\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 782.00 MiB (GPU 0; 39.56 GiB total capacity; 35.73 GiB already allocated; 466.81 MiB free; 38.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["import os\n","import json\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n","from datasets import Dataset\n","from flask import Flask, request, jsonify\n","\n","# Constants\n","MODEL_NAME = \"gorilla-llm/gorilla-openfunctions-v2\"\n","OUTPUT_DIR = \"/content/drive/MyDrive/Project/training/weights\"\n","LOG_DIR = \"/content/drive/MyDrive/Project/training\"\n","TRAIN_DATASET_PATH = \"/content/datasets/train.json\"\n","VAL_DATASET_PATH = \"/content/datasets/val.json\"\n","\n","# Clear GPU memory\n","torch.cuda.empty_cache()\n","\n","# Load the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n","\n","# Load the model\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    device_map=\"auto\",\n","    load_in_8bit=True,\n","    torch_dtype=torch.float16,\n",")\n","model.resize_token_embeddings(len(tokenizer))\n","\n","# Load dataset\n","def load_json_as_dataset(filepath):\n","    with open(filepath, \"r\") as f:\n","        data = json.load(f)\n","    return Dataset.from_list(data)\n","\n","train_dataset = load_json_as_dataset(TRAIN_DATASET_PATH)\n","val_dataset = load_json_as_dataset(VAL_DATASET_PATH)\n","\n","# Preprocessing\n","def preprocess_function(samples):\n","    # Format prompt with input and output\n","    combined_text = (\n","        f\"<s><|system|>\\nYour task is to respond to user queries.\\n\"\n","        f\"<|user|>\\n{samples['input']}\\n<|assistant|>\\n{samples['output']}</s>\"\n","    )\n","\n","    # Tokenize\n","    tokenized = tokenizer(\n","        combined_text,\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=512,\n","        return_tensors=\"pt\"\n","    )\n","\n","    input_ids = tokenized[\"input_ids\"].squeeze()\n","    labels = input_ids.clone()  # Use the entire sequence as labels\n","\n","    return {\n","        \"input_ids\": input_ids,\n","        \"attention_mask\": tokenized[\"attention_mask\"].squeeze(),\n","        \"labels\": labels,\n","    }\n","\n","# Apply preprocessing\n","tokenized_train_dataset = train_dataset.map(preprocess_function)\n","tokenized_val_dataset = val_dataset.map(preprocess_function)\n","\n","# Training arguments\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=100,\n","    logging_dir=LOG_DIR,\n","    logging_steps=10,\n","    per_device_train_batch_size=1,\n","    learning_rate=5e-5,\n","    num_train_epochs=1,\n","    save_strategy=\"epoch\",\n","    save_total_limit=2,\n","    weight_decay=0.01,\n","    report_to=\"none\",\n",")\n","\n","# Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train_dataset,\n","    eval_dataset=tokenized_val_dataset,\n","    tokenizer=tokenizer,\n",")\n","\n","# Train the model\n","print(\"Starting training...\")\n","trainer.train()\n","\n","# Save the fine-tuned model\n","print(\"Saving the fine-tuned model...\")\n","model.save_pretrained(OUTPUT_DIR)\n","tokenizer.save_pretrained(OUTPUT_DIR)\n","print(f\"Model saved successfully in {OUTPUT_DIR}!\")\n","\n","# Test function\n","def test_model(prompt):\n","    instruction = (\n","        f\"<s><|system|>\\nYour task is to respond to user queries.\\n<|user|>\\n{prompt}\\n<|assistant|>\\n\"\n","    )\n","    inputs = tokenizer(instruction, return_tensors=\"pt\", truncation=True, max_length=512).to(\"cuda\")\n","    outputs = model.generate(\n","        input_ids=inputs[\"input_ids\"],\n","        attention_mask=inputs[\"attention_mask\"],\n","        max_length=200,\n","        pad_token_id=tokenizer.pad_token_id,\n","        eos_token_id=tokenizer.eos_token_id,\n","    )\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# Test the model\n","test_prompt = \"Find news articles about AI advancements.\"\n","print(\"Test Response:\", test_model(test_prompt))\n","\n","# Flask deployment\n","app = Flask(__name__)\n","\n","@app.route('/query', methods=['POST'])\n","def query():\n","    data = request.json\n","    prompt = data.get(\"prompt\", \"\")\n","    response = test_model(prompt)\n","    return jsonify({\"response\": response})\n","\n","if __name__ == \"__main__\":\n","    app.run(host=\"0.0.0.0\", port=5000)\n"]},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","# Define the path to the fine-tuned model and tokenizer\n","OUTPUT_DIR = \"/content/drive/MyDrive/Project/training/weights\"\n","\n","# Load the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(OUTPUT_DIR, use_fast=True)\n","\n","# Load the model in 8-bit precision\n","model = AutoModelForCausalLM.from_pretrained(\n","    OUTPUT_DIR,\n","    device_map=\"auto\",  # Automatically assigns the model to the correct devices\n","    load_in_8bit=True,  # Indicates that the model was trained in 8-bit precision\n","    torch_dtype=torch.float16,  # Specify the data type\n",")\n","\n","# Define the inference function\n","def test_model(prompt):\n","    # Format the input prompt\n","    instruction = (\n","        f\"<s><|system|>\\nYour task is to respond to user queries.\\n<|user|>\\n{prompt}\\n<|assistant|>\\n\"\n","    )\n","\n","    # Tokenize the input prompt\n","    inputs = tokenizer(instruction, return_tensors=\"pt\", truncation=True, max_length=512)\n","\n","    # Move inputs to the correct device (determined automatically)\n","    inputs = {key: val.to(model.device) for key, val in inputs.items()}\n","\n","    # Generate the response\n","    outputs = model.generate(\n","        input_ids=inputs[\"input_ids\"],\n","        attention_mask=inputs[\"attention_mask\"],\n","        max_length=200,\n","        pad_token_id=tokenizer.pad_token_id,\n","        eos_token_id=tokenizer.eos_token_id,\n","        num_return_sequences=1,\n","        temperature=0.7,\n","        top_k=50,\n","        top_p=0.95,\n","    )\n","\n","    # Decode and return the generated response\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# Test the inference\n","test_prompt = \"Find news articles about AI advancements.\"\n","response = test_model(test_prompt)\n","print(\"Test Response:\", response)\n"],"metadata":{"id":"kDo8OwAX81cr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hosting grok app to connect with fine-tuned GoEx model"],"metadata":{"id":"H4z9dxnnHrVm"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iqMcV0BjkLxe","outputId":"93171dc8-6253-40c1-f41e-316dbecc71b5","executionInfo":{"status":"ok","timestamp":1734634219102,"user_tz":300,"elapsed":4219,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.2)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n"]}],"source":["!pip install pyngrok"]},{"cell_type":"code","source":["!pip install -U bitsandbytes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EwP9x0_sPOSf","executionInfo":{"status":"ok","timestamp":1734633934669,"user_tz":300,"elapsed":4195,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}},"outputId":"fab02150-1dbf-4507-abd8-b9f6d0756cc1"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n"]}]},{"cell_type":"code","source":["import os\n","with open('/content/drive/My Drive/W6998-DL/Project/NGROK_AUTH.txt', 'r') as file:\n","    NGROK_AUTH_TOKEN = file.read().strip()\n","os.environ['NGROK_AUTH_TOKEN'] = NGROK_AUTH_TOKEN"],"metadata":{"id":"9nO_0SyBL7ex","executionInfo":{"status":"ok","timestamp":1734634219102,"user_tz":300,"elapsed":5,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWS2ceaVjVT7","outputId":"11b8711d-684d-4ad4-ff01-e3109c69750d"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at /content/drive/MyDrive/W6998-DL/Project/training/weights/checkpoint-1209 were not used when initializing LlamaForCausalLM: ['model.layers.2.self_attn.o_proj.weight_format', 'model.layers.1.mlp.down_proj.weight_format', 'model.layers.7.self_attn.q_proj.weight_format', 'model.layers.23.mlp.down_proj.weight_format', 'model.layers.18.self_attn.o_proj.weight_format', 'model.layers.7.mlp.gate_proj.weight_format', 'model.layers.11.mlp.down_proj.weight_format', 'model.layers.18.self_attn.q_proj.weight_format', 'model.layers.25.mlp.up_proj.weight_format', 'model.layers.0.self_attn.o_proj.weight_format', 'model.layers.9.mlp.down_proj.weight_format', 'model.layers.28.self_attn.q_proj.weight_format', 'model.layers.25.self_attn.q_proj.weight_format', 'model.layers.1.self_attn.q_proj.weight_format', 'model.layers.0.self_attn.q_proj.weight_format', 'model.layers.10.mlp.up_proj.weight_format', 'model.layers.7.self_attn.o_proj.weight_format', 'model.layers.4.self_attn.k_proj.weight_format', 'model.layers.3.self_attn.k_proj.weight_format', 'model.layers.21.mlp.up_proj.weight_format', 'model.layers.7.mlp.down_proj.weight_format', 'model.layers.12.self_attn.v_proj.weight_format', 'model.layers.18.mlp.down_proj.weight_format', 'model.layers.15.self_attn.o_proj.weight_format', 'model.layers.11.self_attn.q_proj.weight_format', 'model.layers.16.self_attn.o_proj.weight_format', 'model.layers.4.self_attn.v_proj.weight_format', 'model.layers.7.self_attn.v_proj.weight_format', 'model.layers.0.self_attn.k_proj.weight_format', 'model.layers.4.mlp.down_proj.weight_format', 'model.layers.7.self_attn.k_proj.weight_format', 'model.layers.3.self_attn.q_proj.weight_format', 'model.layers.12.self_attn.q_proj.weight_format', 'model.layers.13.mlp.up_proj.weight_format', 'model.layers.26.mlp.down_proj.weight_format', 'model.layers.3.mlp.down_proj.weight_format', 'model.layers.6.mlp.up_proj.weight_format', 'model.layers.12.self_attn.k_proj.weight_format', 'model.layers.20.mlp.down_proj.weight_format', 'model.layers.9.self_attn.v_proj.weight_format', 'model.layers.6.self_attn.k_proj.weight_format', 'model.layers.6.self_attn.o_proj.weight_format', 'model.layers.17.self_attn.k_proj.weight_format', 'model.layers.1.self_attn.k_proj.weight_format', 'model.layers.17.self_attn.v_proj.weight_format', 'model.layers.16.mlp.up_proj.weight_format', 'model.layers.5.self_attn.v_proj.weight_format', 'model.layers.27.self_attn.o_proj.weight_format', 'model.layers.6.self_attn.q_proj.weight_format', 'model.layers.27.self_attn.v_proj.weight_format', 'model.layers.29.self_attn.o_proj.weight_format', 'model.layers.21.mlp.down_proj.weight_format', 'model.layers.27.mlp.up_proj.weight_format', 'model.layers.20.self_attn.k_proj.weight_format', 'model.layers.15.mlp.down_proj.weight_format', 'model.layers.2.mlp.down_proj.weight_format', 'model.layers.19.mlp.gate_proj.weight_format', 'model.layers.15.self_attn.v_proj.weight_format', 'model.layers.11.mlp.up_proj.weight_format', 'model.layers.8.self_attn.k_proj.weight_format', 'model.layers.13.self_attn.v_proj.weight_format', 'model.layers.8.self_attn.q_proj.weight_format', 'model.layers.19.mlp.up_proj.weight_format', 'model.layers.14.mlp.gate_proj.weight_format', 'model.layers.15.mlp.up_proj.weight_format', 'model.layers.28.mlp.gate_proj.weight_format', 'model.layers.10.self_attn.q_proj.weight_format', 'model.layers.5.self_attn.o_proj.weight_format', 'model.layers.1.mlp.gate_proj.weight_format', 'model.layers.17.self_attn.o_proj.weight_format', 'model.layers.26.self_attn.k_proj.weight_format', 'model.layers.18.self_attn.k_proj.weight_format', 'model.layers.0.self_attn.v_proj.weight_format', 'model.layers.9.self_attn.k_proj.weight_format', 'model.layers.2.self_attn.v_proj.weight_format', 'model.layers.10.mlp.gate_proj.weight_format', 'model.layers.2.self_attn.k_proj.weight_format', 'model.layers.22.mlp.up_proj.weight_format', 'model.layers.29.mlp.down_proj.weight_format', 'model.layers.11.self_attn.k_proj.weight_format', 'model.layers.0.mlp.up_proj.weight_format', 'model.layers.19.self_attn.v_proj.weight_format', 'model.layers.21.self_attn.q_proj.weight_format', 'model.layers.25.mlp.down_proj.weight_format', 'model.layers.13.self_attn.o_proj.weight_format', 'model.layers.2.self_attn.q_proj.weight_format', 'model.layers.14.self_attn.v_proj.weight_format', 'model.layers.25.mlp.gate_proj.weight_format', 'model.layers.2.mlp.up_proj.weight_format', 'model.layers.29.self_attn.k_proj.weight_format', 'model.layers.24.mlp.down_proj.weight_format', 'model.layers.24.self_attn.o_proj.weight_format', 'model.layers.25.self_attn.v_proj.weight_format', 'model.layers.26.mlp.up_proj.weight_format', 'model.layers.28.self_attn.o_proj.weight_format', 'model.layers.5.mlp.down_proj.weight_format', 'model.layers.15.self_attn.q_proj.weight_format', 'model.layers.23.mlp.gate_proj.weight_format', 'model.layers.14.self_attn.q_proj.weight_format', 'model.layers.16.self_attn.q_proj.weight_format', 'model.layers.8.mlp.gate_proj.weight_format', 'model.layers.17.mlp.gate_proj.weight_format', 'model.layers.17.mlp.up_proj.weight_format', 'model.layers.19.self_attn.q_proj.weight_format', 'model.layers.27.self_attn.q_proj.weight_format', 'model.layers.8.mlp.down_proj.weight_format', 'model.layers.8.self_attn.v_proj.weight_format', 'model.layers.11.mlp.gate_proj.weight_format', 'model.layers.29.self_attn.q_proj.weight_format', 'model.layers.26.self_attn.v_proj.weight_format', 'model.layers.22.self_attn.k_proj.weight_format', 'model.layers.11.self_attn.o_proj.weight_format', 'model.layers.22.self_attn.v_proj.weight_format', 'model.layers.20.mlp.gate_proj.weight_format', 'model.layers.20.self_attn.v_proj.weight_format', 'model.layers.20.mlp.up_proj.weight_format', 'model.layers.28.self_attn.v_proj.weight_format', 'model.layers.23.self_attn.q_proj.weight_format', 'model.layers.1.self_attn.v_proj.weight_format', 'model.layers.4.mlp.gate_proj.weight_format', 'model.layers.21.self_attn.k_proj.weight_format', 'model.layers.8.self_attn.o_proj.weight_format', 'model.layers.9.self_attn.o_proj.weight_format', 'model.layers.10.self_attn.k_proj.weight_format', 'model.layers.18.self_attn.v_proj.weight_format', 'model.layers.1.mlp.up_proj.weight_format', 'model.layers.16.mlp.down_proj.weight_format', 'model.layers.4.mlp.up_proj.weight_format', 'model.layers.17.mlp.down_proj.weight_format', 'model.layers.6.mlp.gate_proj.weight_format', 'model.layers.29.mlp.gate_proj.weight_format', 'model.layers.20.self_attn.o_proj.weight_format', 'model.layers.17.self_attn.q_proj.weight_format', 'model.layers.22.self_attn.o_proj.weight_format', 'model.layers.24.mlp.up_proj.weight_format', 'model.layers.20.self_attn.q_proj.weight_format', 'model.layers.0.mlp.down_proj.weight_format', 'model.layers.14.mlp.up_proj.weight_format', 'model.layers.27.self_attn.k_proj.weight_format', 'model.layers.21.self_attn.v_proj.weight_format', 'model.layers.15.mlp.gate_proj.weight_format', 'model.layers.3.mlp.gate_proj.weight_format', 'model.layers.24.mlp.gate_proj.weight_format', 'model.layers.13.mlp.gate_proj.weight_format', 'model.layers.9.self_attn.q_proj.weight_format', 'model.layers.12.mlp.down_proj.weight_format', 'model.layers.9.mlp.gate_proj.weight_format', 'model.layers.26.self_attn.o_proj.weight_format', 'model.layers.12.mlp.up_proj.weight_format', 'model.layers.18.mlp.gate_proj.weight_format', 'model.layers.26.self_attn.q_proj.weight_format', 'model.layers.10.self_attn.v_proj.weight_format', 'model.layers.3.self_attn.o_proj.weight_format', 'model.layers.7.mlp.up_proj.weight_format', 'model.layers.16.self_attn.k_proj.weight_format', 'model.layers.25.self_attn.k_proj.weight_format', 'model.layers.5.self_attn.k_proj.weight_format', 'model.layers.14.self_attn.k_proj.weight_format', 'model.layers.28.self_attn.k_proj.weight_format', 'model.layers.4.self_attn.o_proj.weight_format', 'model.layers.2.mlp.gate_proj.weight_format', 'model.layers.10.mlp.down_proj.weight_format', 'model.layers.28.mlp.down_proj.weight_format', 'model.layers.24.self_attn.q_proj.weight_format', 'model.layers.3.mlp.up_proj.weight_format', 'model.layers.6.mlp.down_proj.weight_format', 'model.layers.1.self_attn.o_proj.weight_format', 'model.layers.16.self_attn.v_proj.weight_format', 'model.layers.12.self_attn.o_proj.weight_format', 'model.layers.0.mlp.gate_proj.weight_format', 'model.layers.14.self_attn.o_proj.weight_format', 'model.layers.26.mlp.gate_proj.weight_format', 'model.layers.22.self_attn.q_proj.weight_format', 'model.layers.10.self_attn.o_proj.weight_format', 'model.layers.28.mlp.up_proj.weight_format', 'model.layers.22.mlp.down_proj.weight_format', 'model.layers.21.self_attn.o_proj.weight_format', 'model.layers.14.mlp.down_proj.weight_format', 'model.layers.11.self_attn.v_proj.weight_format', 'model.layers.12.mlp.gate_proj.weight_format', 'model.layers.23.self_attn.v_proj.weight_format', 'model.layers.27.mlp.gate_proj.weight_format', 'model.layers.6.self_attn.v_proj.weight_format', 'model.layers.15.self_attn.k_proj.weight_format', 'model.layers.13.self_attn.k_proj.weight_format', 'model.layers.19.self_attn.o_proj.weight_format', 'model.layers.29.self_attn.v_proj.weight_format', 'model.layers.27.mlp.down_proj.weight_format', 'model.layers.29.mlp.up_proj.weight_format', 'model.layers.8.mlp.up_proj.weight_format', 'model.layers.23.mlp.up_proj.weight_format', 'model.layers.3.self_attn.v_proj.weight_format', 'model.layers.5.self_attn.q_proj.weight_format', 'model.layers.21.mlp.gate_proj.weight_format', 'model.layers.5.mlp.gate_proj.weight_format', 'model.layers.19.mlp.down_proj.weight_format', 'model.layers.23.self_attn.o_proj.weight_format', 'model.layers.24.self_attn.k_proj.weight_format', 'model.layers.19.self_attn.k_proj.weight_format', 'model.layers.25.self_attn.o_proj.weight_format', 'model.layers.4.self_attn.q_proj.weight_format', 'model.layers.5.mlp.up_proj.weight_format', 'model.layers.9.mlp.up_proj.weight_format', 'model.layers.22.mlp.gate_proj.weight_format', 'model.layers.18.mlp.up_proj.weight_format', 'model.layers.13.self_attn.q_proj.weight_format', 'model.layers.24.self_attn.v_proj.weight_format', 'model.layers.23.self_attn.k_proj.weight_format', 'model.layers.13.mlp.down_proj.weight_format', 'model.layers.16.mlp.gate_proj.weight_format']\n","- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Public URL: NgrokTunnel: \"https://8a27-34-138-80-49.ngrok-free.app\" -> \"http://localhost:5000\"\n"," * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on all addresses (0.0.0.0)\n"," * Running on http://127.0.0.1:5000\n"," * Running on http://172.28.0.12:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n","INFO:werkzeug:127.0.0.1 - - [19/Dec/2024 18:58:27] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n","INFO:werkzeug:127.0.0.1 - - [19/Dec/2024 18:58:28] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n","  warnings.warn(\n","INFO:werkzeug:127.0.0.1 - - [19/Dec/2024 19:06:22] \"POST /query HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [19/Dec/2024 19:06:48] \"POST /query HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [19/Dec/2024 19:07:15] \"POST /query HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [19/Dec/2024 19:07:41] \"POST /query HTTP/1.1\" 200 -\n"]}],"source":["# Install necessary dependencies\n","# for hosting flask pyngrok app\n","\n","# Import libraries\n","from flask import Flask, request, jsonify\n","from pyngrok import ngrok\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","import torch\n","import os\n","from google.colab import userdata\n","\n","\n","# Retrieve ngrok auth token from Colab secrets\n","#ngrok_auth_token = userdata.get(\"NGROK_AUTH_TOKEN\")\n","ngrok_auth_token = os.getenv(\"NGROK_AUTH_TOKEN\")\n","\n","if not ngrok_auth_token:\n","    raise ValueError(\"NGROK_AUTH_TOKEN is not set in Colab Secrets.\")\n","\n","# Authenticate ngrok\n","ngrok.set_auth_token(ngrok_auth_token)\n","\n","# Constants\n","MODEL_DIR = \"/content/drive/MyDrive/W6998-DL/Project/training/weights/checkpoint-1209\"\n","\n","# Load the fine-tuned model and tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n","model = AutoModelForCausalLM.from_pretrained(MODEL_DIR, device_map=\"auto\", torch_dtype=torch.float16)\n","\n","def test_model(prompt):\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","    if \"token_type_ids\" in inputs:\n","        inputs.pop(\"token_type_ids\")\n","    outputs = model.generate(**inputs, max_length=200)\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# Flask app\n","app = Flask(__name__)\n","\n","@app.route('/query', methods=['POST'])\n","def query():\n","    data = request.json\n","    prompt = data.get(\"prompt\", \"\")\n","    response = test_model(prompt)\n","    return jsonify({\"response\": response})\n","\n","if __name__ == \"__main__\":\n","    # Start ngrok tunnel\n","    public_url = ngrok.connect(5000)\n","    print(f\"Public URL: {public_url}\")\n","\n","    # Run the Flask app\n","    app.run(host=\"0.0.0.0\", port=5000)\n"]},{"cell_type":"markdown","metadata":{"id":"4UjUV8Soj8j4"},"source":["## Inference with Finetunes weight files"]},{"cell_type":"markdown","metadata":{"id":"GRkuPuvjmcWk"},"source":["## Sample Inferencing with ngrok app"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xb_KTFcBmgQV"},"outputs":[],"source":["import requests\n","\n","# Define the ngrok public URL for your Flask API\n","url = \"https://8a27-34-138-80-49.ngrok-free.app/query\"\n","\n","# Queries to test the model\n","queries = [\n","    \"Find Google search results for 'Python programming'.\",\n","    \"What is the latest news about artificial intelligence?\",\n","    \"Find recipes for healthy dinner options.\",\n","    \"Tell me about the top tourist attractions in Paris.\"\n","]\n","\n","# Function to query the model\n","def query_model(prompt):\n","    payload = {\"prompt\": prompt}\n","    response = requests.post(url, json=payload)\n","    if response.status_code == 200:\n","        return response.json().get(\"response\", \"No response\")\n","    else:\n","        return f\"Error: {response.status_code}, {response.text}\"\n","\n","# Loop through the queries and display results\n","for query in queries:\n","    print(f\"Query: {query}\")\n","    print(f\"Response: {query_model(query)}\")\n","    print(\"-\" * 80)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b0cf5011544b4912b63edbc60e6d62be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_750b30f20e884889b828feaab80157c0","IPY_MODEL_dce6d0b1f44a49b691ca9a2da593348b","IPY_MODEL_61508d0423f8494db196614cb61bc3fb"],"layout":"IPY_MODEL_b77a66f690984e2da84b470ed424e537"}},"750b30f20e884889b828feaab80157c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a265a4fe32c444cea29678556071b6b6","placeholder":"​","style":"IPY_MODEL_75c82cc98a6f49c0bbe01f56d9be3422","value":"Loading checkpoint shards: 100%"}},"dce6d0b1f44a49b691ca9a2da593348b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9adce390bd05408693efa4ffa38c0ca4","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d43f8aa79c8743e89b189c67adc58778","value":2}},"61508d0423f8494db196614cb61bc3fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14046227eef14344a5766eb3976b473d","placeholder":"​","style":"IPY_MODEL_1ea29e3d899d4caa8fadfebe2e438581","value":" 2/2 [00:17&lt;00:00,  7.99s/it]"}},"b77a66f690984e2da84b470ed424e537":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a265a4fe32c444cea29678556071b6b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75c82cc98a6f49c0bbe01f56d9be3422":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9adce390bd05408693efa4ffa38c0ca4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d43f8aa79c8743e89b189c67adc58778":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"14046227eef14344a5766eb3976b473d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ea29e3d899d4caa8fadfebe2e438581":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3da982024d74f299683633cf1a9108c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_738b08da24cc4ad2820b21054819d3c2","IPY_MODEL_102d7964cd8341899a640f98e602ca3a","IPY_MODEL_239675070c0a40ec880a1d784414bb75"],"layout":"IPY_MODEL_5c06a0690a7c4c89adfaaffdca1bc2d6"}},"738b08da24cc4ad2820b21054819d3c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2980273d9224e0eb66d1014ae7f7b67","placeholder":"​","style":"IPY_MODEL_6d627365d07040be8b56f975fcc245c7","value":"Map:  89%"}},"102d7964cd8341899a640f98e602ca3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b3f3db07fab4c278236430c1edd4d2c","max":403,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d777b7692cd948128a9b6e3e04106488","value":403}},"239675070c0a40ec880a1d784414bb75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c31f52448ef7409dbff3665d345083be","placeholder":"​","style":"IPY_MODEL_0d76746510f1412a96eb1d3204f2f995","value":" 357/403 [00:00&lt;00:00, 506.54 examples/s]"}},"5c06a0690a7c4c89adfaaffdca1bc2d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"f2980273d9224e0eb66d1014ae7f7b67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d627365d07040be8b56f975fcc245c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b3f3db07fab4c278236430c1edd4d2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d777b7692cd948128a9b6e3e04106488":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c31f52448ef7409dbff3665d345083be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d76746510f1412a96eb1d3204f2f995":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a9fec0dd77748a7aedb8ea057f8f9bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_00fda95070974d5aa657f8c9a2f81671","IPY_MODEL_30b4ba00f7ca4628ae50a5e439f03f07","IPY_MODEL_87a36cc2f4d84eef86acd8119ca01505"],"layout":"IPY_MODEL_b1b235e04fea48b08b77a62c64d03ca4"}},"00fda95070974d5aa657f8c9a2f81671":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00b5b2faefe1446d88c72625f8b6cb9e","placeholder":"​","style":"IPY_MODEL_569d3bc76c34488cb51447dc4871c809","value":"Map: 100%"}},"30b4ba00f7ca4628ae50a5e439f03f07":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd32a3e27f1d459ca9295d0365b49c2d","max":101,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21cd70ca04ae4ef78e58639d0f4dc979","value":101}},"87a36cc2f4d84eef86acd8119ca01505":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca1011b33a12421f9295b14dcc22e4e8","placeholder":"​","style":"IPY_MODEL_ac4b3240b5ca4214a430b06a0a5e81de","value":" 101/101 [00:00&lt;00:00, 458.98 examples/s]"}},"b1b235e04fea48b08b77a62c64d03ca4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"00b5b2faefe1446d88c72625f8b6cb9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"569d3bc76c34488cb51447dc4871c809":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd32a3e27f1d459ca9295d0365b49c2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21cd70ca04ae4ef78e58639d0f4dc979":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca1011b33a12421f9295b14dcc22e4e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac4b3240b5ca4214a430b06a0a5e81de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}