{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["9cB8sb-Qi62u","n9XZ1bi4jCd6","m6OXtz8IjGd4"],"authorship_tag":"ABX9TyMDU4//dzIQ1AgyHhnrzyZu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Initial Setup"],"metadata":{"id":"9cB8sb-Qi62u"}},{"cell_type":"code","source":["!pip install openai==0.28.1 &> /dev/null"],"metadata":{"id":"iDPGjiW0jemU","executionInfo":{"status":"ok","timestamp":1733867472311,"user_tz":300,"elapsed":4462,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["import os\n","from typing import List, Dict\n","import requests\n"],"metadata":{"id":"XfJhpFdxO1yz","executionInfo":{"status":"ok","timestamp":1733862237217,"user_tz":300,"elapsed":112,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QzaVwXczO6JM","executionInfo":{"status":"ok","timestamp":1733880991168,"user_tz":300,"elapsed":1220,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}},"outputId":"dd0e54b9-c390-46db-9b5e-a6564aa93b0e"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Vdhd4A3hOq9M","executionInfo":{"status":"ok","timestamp":1733862062708,"user_tz":300,"elapsed":236,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}}},"outputs":[],"source":["os.environ['NEWS_API_KEY'] = '1b011360de6b4867ae0a17d1fff77de3'"]},{"cell_type":"markdown","source":["## New API"],"metadata":{"id":"n9XZ1bi4jCd6"}},{"cell_type":"code","source":["from dateutil import parser\n","from langchain.tools import tool\n","\n","@tool\n","def news_search(query: str) -> List[Dict[str, str]]:\n","    \"\"\"\n","    Searches for news headlines based on the provided query.\n","\n","    Parameters:\n","    query (str): The search query for fetching relevant news headlines.\n","\n","    Returns:\n","    List[Dict[str, str]]: A list of dictionaries containing news headline, source, and date.\n","    \"\"\"\n","    # Example API setup (replace `YOUR_NEWS_API_KEY` with your actual key)\n","    #api_key = '1b011360de6b4867ae0a17d1fff77de3'\n","    api_key = os.getenv(\"NEWS_API_KEY\")\n","    url = f'https://newsapi.org/v2/everything?q={query}&apiKey={api_key}'\n","\n","    try:\n","        response = requests.get(url)\n","        response.raise_for_status()\n","        articles = response.json().get(\"articles\", [])\n","\n","        if not articles:\n","            return [{\"error\": \"No articles found for this query.\"}]\n","\n","        # Return at least 3 articles or less if fewer available\n","        return [\n","            {\n","                \"headline\": article[\"title\"],\n","                \"source\": article[\"source\"][\"name\"],\n","                #\"date\": datetime.fromisoformat(article[\"publishedAt\"]).strftime('%Y-%m-%d')\n","                \"date\": parser.parse(article[\"publishedAt\"]).strftime('%Y-%m-%d')\n","            }\n","            for article in articles[:3]\n","        ] or [{\"error\": \"No articles found for this query.\"}]\n","    except requests.exceptions.RequestException as e:\n","        return [{\"error\": f\"API request failed: {str(e)}\"}]\n","    except KeyError:\n","        return [{\"error\": \"Unexpected response format from news API.\"}]\n"],"metadata":{"id":"oUvfS_AZPDnG","executionInfo":{"status":"ok","timestamp":1733862246115,"user_tz":300,"elapsed":147,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Example use cases for NewsSearchTool\n","result = news_search.invoke(\"New York News for today\")\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Pcp1mzwPSMp","executionInfo":{"status":"ok","timestamp":1733862307604,"user_tz":300,"elapsed":984,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}},"outputId":"5958f6de-a401-4f62-8aa5-fd0fb2ec59ed"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'headline': 'New York Times Tech Guild Ends Strike Without a Deal', 'source': 'Gizmodo.com', 'date': '2024-11-12'}, {'headline': 'Ford’s new electric Puma Gen-E looks like a mini-Mustang Mach-E', 'source': 'The Verge', 'date': '2024-12-03'}, {'headline': 'OpenAI sued by Canada’s biggest media outlets', 'source': 'The Verge', 'date': '2024-11-29'}]\n"]}]},{"cell_type":"markdown","source":["## GoEx Framework Init"],"metadata":{"id":"m6OXtz8IjGd4"}},{"cell_type":"code","source":["# Import Chat completion template and set-up variables\n","import openai\n","import urllib.parse\n","\n","openai.api_key = \"EMPTY\" # Key is ignored and does not matter\n","openai.api_base = \"http://zanino.millennium.berkeley.edu:8000/v1\"\n","# Alternate mirrors\n","# openai.api_base = \"http://34.132.127.197:8000/v1\"\n","\n","# Report issues\n","def raise_issue(e, model, prompt):\n","    issue_title = urllib.parse.quote(\"[bug] Hosted Gorilla: <Issue>\")\n","    issue_body = urllib.parse.quote(f\"Exception: {e}\\nFailed model: {model}, for prompt: {prompt}\")\n","    issue_url = f\"https://github.com/ShishirPatil/gorilla/issues/new?assignees=&labels=hosted-gorilla&projects=&template=hosted-gorilla-.md&title={issue_title}&body={issue_body}\"\n","    print(f\"An exception has occurred: {e} \\nPlease raise an issue here: {issue_url}\")\n","\n","# Query Gorilla server\n","def get_gorilla_response(prompt=\"I would like to translate from English to French.\", model=\"gorilla-7b-hf-v1\"):\n","  try:\n","    completion = openai.ChatCompletion.create(\n","      model=model,\n","      messages=[{\"role\": \"user\", \"content\": prompt}]\n","    )\n","    return completion.choices[0].message.content\n","  except Exception as e:\n","    raise_issue(e, model, prompt)"],"metadata":{"id":"ktoOwSLNjJNI","executionInfo":{"status":"ok","timestamp":1733867480358,"user_tz":300,"elapsed":142,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["prompt = \"I would like to translate 'I feel very good today.' from English to Chinese.\"\n","print(get_gorilla_response(prompt, model=\"gorilla-7b-hf-v1\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dFgAu8VKt5lJ","executionInfo":{"status":"ok","timestamp":1733870217129,"user_tz":300,"elapsed":11690,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}},"outputId":"ebc8c14c-9d40-4257-8078-776288098d00"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["<<<domain>>>: Natural Language Processing Translation\n","<<<api_call>>>: translation = pipeline('translation_en_to_zh', model='Helsinki-NLP/opus-mt-en-zh')\n","<<<api_provider>>>: Hugging Face Transformers\n","<<<explanation>>>: 1. Import the necessary components from the Hugging Face Transformers library.\n","2. Initialize the translation pipeline with the model for English to Chinese translation.\n","3. Translate the input text from English to Chinese.\n","<<<code>>>:\n","from transformers import pipeline\n","\n","def load_model():\n","    model = 'Helsinki-NLP/opus-mt-en-zh'\n","    translation = pipeline('translation_en_to_zh', model=model)\n","    return translation\n","\n","def process_data(text, translation):\n","    response = translation(text, max_length=100)[0]['translation_text']\n","    return response\n","\n","text = 'I feel very good today.'\n","\n","# Load the model\n","translation = load_model()\n","# Process the data\n","response = process_data(text, translation)\n","\n","print(response)\n"]}]},{"cell_type":"code","source":["# Gorilla `gorilla-mpt-7b-hf-v1` with code snippets\n","# Translation\n","#prompt = \"I would like to translate 'I feel very good today.' from English to Chinese.\"\n","prompt = \"I would like to get the latest stock price of META.\"\n","print(get_gorilla_response(prompt, model=\"gorilla-7b-hf-v1\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uNdSDdbujjFy","executionInfo":{"status":"ok","timestamp":1733869978133,"user_tz":300,"elapsed":16266,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}},"outputId":"54d0309c-798f-4ffc-b8a1-9248f37de18a"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["<<<domain>>>: Natural Language Processing Text2Text Generation\n","<<<api_call>>>: model = T5ForConditionalGeneration.from_pretrained('t5-3b')\n","<<<api_provider>>>: Hugging Face Transformers\n","<<<explanation>>>:1. Import the necessary components from Hugging Face Transformers, including T5Tokenizer and T5ForConditionalGeneration.\n","2. Load the pretrained T5-3B model and tokenizer.\n","3. Encode the input text (stock symbol) into a token format required by the model.\n","4. Generate the output text (latest stock price) by passing the encoded input to the model.<<<code>>>:\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","\n","def load_model():\n","    tokenizer = T5Tokenizer.from_pretrained('t5-3b')\n","    model = T5ForConditionalGeneration.from_pretrained('t5-3b')\n","    return tokenizer, model\n","\n","def process_data(stock_symbol, tokenizer, model):\n","    encoded_input = tokenizer.encode(stock_symbol, return_tensors='pt')\n","    output_tokens = model.generate(encoded_input)\n","    response = tokenizer.decode(output_tokens[0])\n","    return response\n","\n","stock_symbol = 'META'\n","\n","# Load the model and tokenizer\n","tokenizer, model = load_model()\n","\n","# Process the data\n","response = process_data(stock_symbol, tokenizer, model)\n","print(response)\n"]}]},{"cell_type":"code","source":["#prompt = \"I would like to translate 'I feel very good today.' from English to Chinese.\"\n","prompt = \"what is the latest NEWS in New York city.\"\n","print(get_gorilla_response(prompt, model=\"gorilla-7b-hf-v1\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xqqTv3eUtd3x","executionInfo":{"status":"ok","timestamp":1733870131198,"user_tz":300,"elapsed":22709,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}},"outputId":"13683b3f-e54e-433d-b991-b163dbd21058"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["<<<domain>>>: Natural Language Processing Text Classification\n","<<<api_call>>>: model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-MiniLM-L-6-v2')\n","<<<api_provider>>>: Hugging Face Transformers\n","<<<explanation>>>: 1. Import the necessary components from the Hugging Face Transformers library, such as the AutoTokenizer and AutoModelForSequenceClassification.\n","2. Load the pretrained model with the given model name.\n","3. Tokenize the input text using the tokenizer and truncate the text if necessary.\n","4. Pass the tokenized input to the model and obtain the logits as output.\n","5. Determine the predicted label with the highest logit score.\n","<<<code>>>:\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","\n","def load_model(model_name):\n","    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    return model, tokenizer\n","\n","def process_data(text, model, tokenizer):\n","    # Tokenize and truncate the input text\n","    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors='pt')\n","    # Pass the input to the model and obtain logits\n","    with torch.no_grad():\n","        output = model(**inputs).logits\n","    # Get the predicted label\n","    predicted_label = output.argmax(dim=-1).item()\n","    response = model.config.id2label[predicted_label]\n","    return response\n","\n","# Input text\n","text = 'New York city has been voted the best city to live in the U.S. for the third year in a row.'\n","model_name = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n","\n","# Load the model and tokenizer\n","model, tokenizer = load_model(model_name)\n","\n","# Process the data\n","response = process_data(text, model, tokenizer)\n","print(response)\n"]}]},{"cell_type":"markdown","source":["## GoEx using FineTuned Model"],"metadata":{"id":"igkpTnoHNBGA"}},{"cell_type":"markdown","source":["**dowloding base model**"],"metadata":{"id":"JehjXprUWGnk"}},{"cell_type":"code","source":["!pip install transformers huggingface_hub\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"6yrB2SFNWKBg","executionInfo":{"status":"ok","timestamp":1733880767030,"user_tz":300,"elapsed":7677,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}},"outputId":"de85668a-eb58-44ba-c000-475493cf0cdf"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"]}]},{"cell_type":"code","source":["from huggingface_hub import login\n","login(\"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\")\n"],"metadata":{"id":"U-b_q60bWMvM","executionInfo":{"status":"ok","timestamp":1733880838079,"user_tz":300,"elapsed":518,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","os.environ[\"HF_TOKEN\"] = \"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\"  # Replace with your Hugging Face token\n"],"metadata":{"id":"1os-0jgZWh7o","executionInfo":{"status":"ok","timestamp":1733880853200,"user_tz":300,"elapsed":144,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tuD8CBM1Wvh5","executionInfo":{"status":"ok","timestamp":1733880908512,"user_tz":300,"elapsed":397,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}},"outputId":"2f507c9a-3842-429e-f8da-edc9e7170433"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","model_name = \"gorilla-7b-hf-v1\"  # Replace with the correct model name\n","local_dir = \"/content/drive/MyDrive/W6998-DL/Project/training/gorilla_model\"  # Directory where the model will be saved\n","\n","# Download and save the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=local_dir, use_auth_token=True)\n","\n","# Download and save the model\n","model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=local_dir, use_auth_token=True)\n","\n","print(\"Model and tokenizer have been downloaded to:\", local_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":773},"id":"8TTd7v9CWjyZ","executionInfo":{"status":"error","timestamp":1733880981560,"user_tz":300,"elapsed":332,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}},"outputId":"6f3f6c53-d16f-4296-9866-4c9d94c65b3e"},"execution_count":34,"outputs":[{"output_type":"error","ename":"OSError","evalue":"gorilla-7b-hf-v1 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/gorilla-7b-hf-v1/resolve/main/tokenizer_config.json","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    863\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1377\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1297\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-6758ec9a-6aceb9125cf39b4d1735829c;d119b6a6-5afd-401a-8dd7-7cffc987098b)\n\nRepository Not Found for url: https://huggingface.co/gorilla-7b-hf-v1/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-afa313213436>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Download and save the tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Download and save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m         ) from e\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: gorilla-7b-hf-v1 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","# Load the gorilla-7b-hf-v1 model\n","tokenizer = AutoTokenizer.from_pretrained(\"gorilla-7b-hf-v1\")\n","model = AutoModelForCausalLM.from_pretrained(\"gorilla-7b-hf-v1\")\n","\n","# Input: NYC news article\n","news_input = \"Severe flooding predicted in NYC this weekend.\"\n","\n","# Generate campaign action\n","inputs = tokenizer(f\"Generate actions for: {news_input}\", return_tensors=\"pt\")\n","outputs = model.generate(**inputs, max_length=100)\n","action_plan = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","print(action_plan)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":914},"id":"MqgE9r_-NFUD","executionInfo":{"status":"error","timestamp":1733878744812,"user_tz":300,"elapsed":15450,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}},"outputId":"e6295275-0d37-4305-e564-3b33f1099fcd"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"error","ename":"OSError","evalue":"gorilla-7b-hf-v1 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/gorilla-7b-hf-v1/resolve/main/tokenizer_config.json","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    863\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1377\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1297\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-6758e3dd-46685cae47ebd0732a22c860;63a78507-efff-44c2-a3d2-ff005a587d69)\n\nRepository Not Found for url: https://huggingface.co/gorilla-7b-hf-v1/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-e0ba850a3036>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the gorilla-7b-hf-v1 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gorilla-7b-hf-v1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gorilla-7b-hf-v1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m         ) from e\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: gorilla-7b-hf-v1 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"]}]},{"cell_type":"markdown","source":["## System Integration - Hubspot"],"metadata":{"id":"Y6lVeYBlOyhq"}},{"cell_type":"code","source":["HUBSPOT_API_KEY = \"ab24ad08-6ae9-485f-8a83-7f07471dfd1e\"\n"],"metadata":{"id":"Huu8X_PpOyEw","executionInfo":{"status":"ok","timestamp":1733880037731,"user_tz":300,"elapsed":145,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["#defining action item\n","{\n","  \"action\": \"send_email\",\n","  \"details\": {\n","    \"email\": \"user@example.com\",\n","    \"subject\": \"Insurance Offer for NYC Residents\",\n","    \"body\": \"We have a special offer for flood insurance. Contact us today!\"\n","  }\n","}\n"],"metadata":{"id":"uPCiZUnRRZI9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","\n","# HubSpot API base URL\n","HUBSPOT_API_BASE = \"https://api.hubapi.com\"\n","\n","# Function: Create or Update a Contact\n","def create_or_update_contact(email, first_name=None, last_name=None, properties=None):\n","    url = f\"{HUBSPOT_API_BASE}/crm/v3/objects/contacts\"\n","    headers = {\"Authorization\": f\"Bearer {HUBSPOT_API_KEY}\", \"Content-Type\": \"application/json\"}\n","\n","    # Prepare payload\n","    payload = {\n","        \"properties\": {\n","            \"email\": email,\n","            \"firstname\": first_name,\n","            \"lastname\": last_name,\n","            **(properties or {})\n","        }\n","    }\n","\n","    response = requests.post(url, json=payload, headers=headers)\n","    return response.json()\n","\n","# Function: Send Email\n","def send_email(to_email, subject, body):\n","    url = f\"{HUBSPOT_API_BASE}/email/public/v1/singleEmail/send\"\n","    headers = {\"Authorization\": f\"Bearer {HUBSPOT_API_KEY}\", \"Content-Type\": \"application/json\"}\n","\n","    # Prepare payload\n","    payload = {\n","        \"to\": to_email,\n","        \"subject\": subject,\n","        \"html\": body  # HTML content for the email\n","    }\n","\n","    response = requests.post(url, json=payload, headers=headers)\n","    return response.json()\n","\n","# Example Workflow\n","def process_action(action):\n","    if action[\"action\"] == \"send_email\":\n","        email = action[\"details\"][\"email\"]\n","        subject = action[\"details\"][\"subject\"]\n","        body = action[\"details\"][\"body\"]\n","\n","        # Optional: Create or update the contact\n","        create_or_update_contact(email=email, first_name=\"John\", last_name=\"Doe\")\n","\n","        # Send the email\n","        email_response = send_email(to_email=email, subject=subject, body=body)\n","        return email_response\n","\n","# Example Action Item\n","action_item = {\n","    \"action\": \"send_email\",\n","    \"details\": {\n","        \"email\": \"jane.doe@example.com\",\n","        \"subject\": \"Exclusive Insurance Offer\",\n","        \"body\": \"<h1>Special NYC Offer</h1><p>Get your insurance today!</p>\"\n","    }\n","}\n","\n","# Process the Action\n","response = process_action(action_item)\n","print(response)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4VbbFqZbRnQx","executionInfo":{"status":"ok","timestamp":1733880042059,"user_tz":300,"elapsed":449,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}},"outputId":"9c0053cb-e126-4d70-cf6a-3e4bbc0f39e4"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["{'status': 'error', 'message': 'Authentication credentials not found. This API supports OAuth 2.0 authentication and you can find more details at https://developers.hubspot.com/docs/methods/auth/oauth-overview', 'correlationId': 'f019a60a-6772-4210-8992-ab247d7c83c8', 'category': 'INVALID_AUTHENTICATION'}\n"]}]},{"cell_type":"code","source":["#Error Handling in case of non connectivity\n","try:\n","    response = process_action(action_item)\n","    if response.status_code != 200:\n","        raise Exception(f\"Failed with status code {response.status_code}\")\n","except Exception as e:\n","    print(f\"Error: {e}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-3kxxzWFRqmx","executionInfo":{"status":"ok","timestamp":1733880053695,"user_tz":300,"elapsed":469,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}},"outputId":"4460c27d-fe42-4b8c-b28b-a339eb5266df"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Error: 'dict' object has no attribute 'status_code'\n"]}]},{"cell_type":"markdown","source":["## Loggin Action"],"metadata":{"id":"naeaOa73R64K"}},{"cell_type":"markdown","source":["**Actio Log Format**\n","\n","{\n","  \"id\": \"action_001\",\n","  \"timestamp\": \"2024-12-10T10:00:00Z\",\n","  \"action\": \"send_email\",\n","  \"status\": \"success\",\n","  \"details\": {\n","    \"email\": \"user@example.com\",\n","    \"subject\": \"Insurance Offer\",\n","    \"body\": \"We have a special offer for flood insurance.\",\n","    \"system\": \"HubSpot\"\n","  },\n","  \"reversible\": true\n","}\n"],"metadata":{"id":"5t1eyePbSO5i"}},{"cell_type":"code","source":["import json\n","from datetime import datetime\n","import uuid\n","\n","# Log file path\n","LOG_FILE = \"action_log.json\"\n","\n","# Function: Log Action\n","def log_action(action_id, action_type, status, details, reversible):\n","    log_entry = {\n","        \"id\": action_id,\n","        \"timestamp\": datetime.utcnow().isoformat(),\n","        \"action\": action_type,\n","        \"status\": status,\n","        \"details\": details,\n","        \"reversible\": reversible\n","    }\n","\n","    # Append to log file\n","    try:\n","        with open(LOG_FILE, \"a\") as log_file:\n","            log_file.write(json.dumps(log_entry) + \"\\n\")\n","    except Exception as e:\n","        print(f\"Error logging action: {e}\")\n","\n","# Example Usage\n","log_action(\n","    action_id=str(uuid.uuid4()),\n","    action_type=\"send_email\",\n","    status=\"success\",\n","    details={\n","        \"email\": \"user@example.com\",\n","        \"subject\": \"Insurance Offer\",\n","        \"body\": \"We have a special offer for flood insurance.\",\n","        \"system\": \"HubSpot\"\n","    },\n","    reversible=True\n",")\n"],"metadata":{"id":"1aGU2upBR4XS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Action Reversal"],"metadata":{"id":"hWr2RefSUB8A"}},{"cell_type":"code","source":["# Function: Reverse Action\n","def reverse_action(action_id):\n","    # Load logs\n","    try:\n","        with open(LOG_FILE, \"r\") as log_file:\n","            logs = [json.loads(line) for line in log_file.readlines()]\n","    except Exception as e:\n","        print(f\"Error reading log file: {e}\")\n","        return {\"status\": \"error\", \"message\": str(e)}\n","\n","    # Find the action to reverse\n","    action_to_reverse = next((log for log in logs if log[\"id\"] == action_id), None)\n","    if not action_to_reverse:\n","        return {\"status\": \"error\", \"message\": \"Action not found.\"}\n","\n","    if not action_to_reverse[\"reversible\"]:\n","        return {\"status\": \"error\", \"message\": \"Action is not reversible.\"}\n","\n","    # Perform reversal based on action type\n","    action_type = action_to_reverse[\"action\"]\n","    details = action_to_reverse[\"details\"]\n","\n","    if action_type == \"send_email\":\n","        # Example reversal: Mark email as recalled (or notify the recipient)\n","        print(f\"Reversing email sent to {details['email']}\")\n","        # Add actual email recall logic here\n","\n","    elif action_type == \"update_contact\":\n","        # Rollback contact update\n","        print(f\"Rolling back contact update for {details['email']}\")\n","        # Add actual rollback logic here\n","\n","    else:\n","        return {\"status\": \"error\", \"message\": f\"Reversal not implemented for action type {action_type}.\"}\n","\n","    return {\"status\": \"success\", \"message\": \"Action reversed successfully.\"}\n","\n","# Example Usage\n","response = reverse_action(\"action_001\")\n","print(response)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HERwjfgTUDvH","executionInfo":{"status":"ok","timestamp":1733880209104,"user_tz":300,"elapsed":318,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}},"outputId":"65ccd870-e6b4-4c97-bfa5-bf196ed2bc23"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Error reading log file: name 'LOG_FILE' is not defined\n","{'status': 'error', 'message': \"name 'LOG_FILE' is not defined\"}\n"]}]},{"cell_type":"markdown","source":["## Loggin and Reversal"],"metadata":{"id":"M-HYFWsAUPsN"}},{"cell_type":"code","source":["# Example Workflow\n","def process_action_with_logging(action):\n","    action_id = str(uuid.uuid4())\n","    try:\n","        # Perform the action\n","        response = process_action(action)\n","        status = \"success\" if response[\"status\"] == \"ok\" else \"failure\"\n","\n","        # Log the action\n","        log_action(\n","            action_id=action_id,\n","            action_type=action[\"action\"],\n","            status=status,\n","            details=action[\"details\"],\n","            reversible=True\n","        )\n","\n","        return response\n","    except Exception as e:\n","        # Log the error\n","        log_action(\n","            action_id=action_id,\n","            action_type=action[\"action\"],\n","            status=\"failure\",\n","            details=action[\"details\"],\n","            reversible=False\n","        )\n","        return {\"status\": \"error\", \"message\": str(e)}\n","\n","# Example Action\n","action_item = {\n","    \"action\": \"send_email\",\n","    \"details\": {\n","        \"email\": \"jane.doe@example.com\",\n","        \"subject\": \"Exclusive Insurance Offer\",\n","        \"body\": \"<h1>Special NYC Offer</h1><p>Get your insurance today!</p>\"\n","    }\n","}\n","\n","response = process_action_with_logging(action_item)\n","print(response)\n"],"metadata":{"id":"tfVC2pTQUGyc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Using COT (Chain of Thought) In Action Planning with OpenAI"],"metadata":{"id":"M6penAuKUUIU"}},{"cell_type":"markdown","source":["Analyze the news: \"Severe flooding predicted in NYC this weekend.\"\n","Generate actions to address this news, explaining each step.\n"],"metadata":{"id":"oGzHkfCkUeH1"}},{"cell_type":"markdown","source":["1. Identify potential insurance products relevant to flooding: Flood Insurance.\n","2. Determine the affected demographic: NYC residents in flood-prone areas.\n","3. Create a campaign to highlight flood insurance benefits, targeting NYC residents.\n","4. Notify the marketing system to execute the campaign via email.\n","5. Send a follow-up to stakeholders for monitoring campaign performance.\n"],"metadata":{"id":"pxrAl_iLUjL-"}},{"cell_type":"code","source":["# Example: Infuse CoT into action generation\n","news_input = \"Severe flooding predicted in NYC this weekend.\"\n","\n","# Prompt with reasoning steps\n","prompt = f\"Analyze the news: \\\"{news_input}\\\". Generate actions with explanations for each step.\"\n","inputs = tokenizer(prompt, return_tensors=\"pt\")\n","outputs = model.generate(**inputs, max_length=300)\n","reasoned_actions = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","print(reasoned_actions)\n"],"metadata":{"id":"nSMDaIrbURYg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**logging actions, include reasoning**\n","{\n","  \"id\": \"action_001\",\n","  \"timestamp\": \"2024-12-10T10:00:00Z\",\n","  \"action\": \"send_email\",\n","  \"status\": \"success\",\n","  \"details\": {\n","    \"email\": \"user@example.com\",\n","    \"subject\": \"Insurance Offer for NYC Residents\",\n","    \"body\": \"We have a special offer for flood insurance.\"\n","  },\n","  \"reasoning\": [\n","    \"Severe flooding predicted in NYC this weekend.\",\n","    \"Flood Insurance is relevant to mitigate risks for NYC residents.\",\n","    \"Email campaigns are effective in reaching out to affected individuals quickly.\"\n","  ],\n","  \"reversible\": true\n","}\n"],"metadata":{"id":"nmzwzxIEUryu"}},{"cell_type":"code","source":["# Log with CoT reasoning\n","reasoning_steps = [\n","    \"Severe flooding predicted in NYC this weekend.\",\n","    \"Flood Insurance is relevant to mitigate risks for NYC residents.\",\n","    \"Email campaigns are effective in reaching out to affected individuals quickly.\"\n","]\n","\n","log_action(\n","    action_id=str(uuid.uuid4()),\n","    action_type=\"send_email\",\n","    status=\"success\",\n","    details={\n","        \"email\": \"user@example.com\",\n","        \"subject\": \"Insurance Offer for NYC Residents\",\n","        \"body\": \"We have a special offer for flood insurance.\"\n","    },\n","    reversible=True,\n","    reasoning=reasoning_steps\n",")\n"],"metadata":{"id":"2StAdR9qVAHr","executionInfo":{"status":"ok","timestamp":1733880453023,"user_tz":300,"elapsed":160,"user":{"displayName":"Vaibhaw Kumar Shende","userId":"04360318888797241836"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["**Using Open AI**"],"metadata":{"id":"qgLMqzcmVL-u"}},{"cell_type":"code","source":["import openai\n","\n","# OpenAI API Key\n","openai.api_key = \"your_openai_api_key\"\n","\n","# Define the prompt\n","prompt = \"\"\"\n","Analyze the following scenario step-by-step and generate an action plan.\n","\n","Scenario: Severe flooding is predicted in NYC this weekend. We need to create a marketing campaign to promote flood insurance to NYC residents.\n","\n","Provide a step-by-step explanation for the actions you recommend.\n","\"\"\"\n","\n","# Generate CoT response\n","response = openai.Completion.create(\n","    engine=\"text-davinci-003\",  # Use GPT-4 if available\n","    prompt=prompt,\n","    max_tokens=300,\n","    temperature=0.7,\n","    n=1\n",")\n","\n","# Extract and print the output\n","action_plan = response[\"choices\"][0][\"text\"].strip()\n","print(\"Action Plan with CoT Reasoning:\")\n","print(action_plan)\n"],"metadata":{"id":"z2BTg6epVQUU"},"execution_count":null,"outputs":[]}]}